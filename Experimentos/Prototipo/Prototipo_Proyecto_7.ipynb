{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YkowGkndT9jG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install lazypredict\n",
        "!pip install plotly_express\n",
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OuX3f3cM-VEX"
      },
      "outputs": [],
      "source": [
        "#%%writefile C:/Users/gcruz_li35hm9/Desktop/Bootcamp UDD Ciencia de Datos/Proyecto 7/Categorizador/modelo_predictivo.py\n",
        "\n",
        "from pandas import DataFrame, read_csv, to_numeric, read_pickle\n",
        "from numpy import concatenate, nan\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from google.colab import files \n",
        "\n",
        "\n",
        "\n",
        "class ModeloPredictivo:\n",
        "    def __init__(self, df=None):\n",
        "        self.df = df\n",
        "        self.df_google_sin_duplicados = None\n",
        "        self.df_x_train_transformed = None\n",
        "        self.df_x_test_transformed = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.model = None\n",
        "        self.numerical_scaler = None\n",
        "        self.object_scaler = None\n",
        "\n",
        "    def eliminar_duplicados(self):\n",
        "        self.df.drop(10472, inplace=True)  # Eliminar la fila 10472\n",
        "        self.df_google_sin_duplicados = self.df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    def convertir_reviews(self):\n",
        "        self.df_google_sin_duplicados['Reviews'] = self.df_google_sin_duplicados['Reviews'].str.replace(',', '')\n",
        "        self.df_google_sin_duplicados['Reviews'] = to_numeric(self.df_google_sin_duplicados['Reviews'], errors='coerce')\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_size(size):\n",
        "        if isinstance(size, str):\n",
        "            size = size.strip()\n",
        "            if size.endswith('M'):\n",
        "                return float(size[:-1]) * 1_000\n",
        "            elif size.endswith('k'):\n",
        "                return float(size[:-1])\n",
        "            elif size == 'Varies with device':\n",
        "                return nan\n",
        "            else:\n",
        "                try:\n",
        "                    return float(size)\n",
        "                except ValueError:\n",
        "                    return nan\n",
        "        return nan\n",
        "\n",
        "    def convertir_tamano(self):\n",
        "        self.df_google_sin_duplicados['Size'] = self.df_google_sin_duplicados['Size'].apply(self.convert_size).astype(float)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_installs(installs):\n",
        "        if isinstance(installs, str):\n",
        "            installs_clean = installs.replace(',', '').replace('+', '')\n",
        "            if installs_clean.isdigit():\n",
        "                return int(installs_clean)\n",
        "        return nan\n",
        "\n",
        "    def convertir_installs(self):\n",
        "        self.df_google_sin_duplicados['Installs'] = self.df_google_sin_duplicados['Installs'].apply(self.convert_installs).astype(float)\n",
        "\n",
        "    def imputar_nans(self):\n",
        "        self.df_google_sin_duplicados[\"Rating\"] = self.df_google_sin_duplicados[\"Rating\"].fillna(self.df_google_sin_duplicados[\"Rating\"].median())\n",
        "        self.df_google_sin_duplicados[\"Size\"] = self.df_google_sin_duplicados[\"Size\"].fillna(self.df_google_sin_duplicados[\"Size\"].mean())\n",
        "        self.df_google_sin_duplicados[\"Type\"] = self.df_google_sin_duplicados[\"Type\"].fillna(\"Free\")\n",
        "        self.df_google_sin_duplicados[\"Current Ver\"] = self.df_google_sin_duplicados[\"Current Ver\"].fillna(\"Varies with device\")\n",
        "        self.df_google_sin_duplicados[\"Android Ver\"] = self.df_google_sin_duplicados[\"Android Ver\"].fillna(\"4.1 and up\")\n",
        "\n",
        "    @staticmethod\n",
        "    def rango_intercuartilico(columna):\n",
        "        Q1 = columna.quantile(0.25)\n",
        "        Q3 = columna.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        valor_min = Q1 - (1.5 * IQR)\n",
        "        valor_max = Q3 + (1.5 * IQR)\n",
        "        return valor_min, valor_max\n",
        "\n",
        "    def imputar_outliers(self, columns):\n",
        "        for col in columns:\n",
        "            inf, sup = self.rango_intercuartilico(self.df_google_sin_duplicados[col])\n",
        "            self.df_google_sin_duplicados[col] = self.df_google_sin_duplicados[col].apply(lambda x: inf if x < inf else sup if x > sup else x)\n",
        "\n",
        "    def preparar_datos(self):\n",
        "        y = self.df_google_sin_duplicados[['Rating']]\n",
        "        x = self.df_google_sin_duplicados.drop(columns=\"Rating\", axis=1)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42, shuffle=True)\n",
        "\n",
        "        numeric_cols = x.select_dtypes(include=[\"float64\", \"int64\"])\n",
        "        categorical_cols = x.select_dtypes(include=\"object\")\n",
        "\n",
        "        self.object_scaler = TargetEncoder(cols=categorical_cols.columns)\n",
        "        self.numerical_scaler = StandardScaler()\n",
        "\n",
        "        x_train_num = x_train.select_dtypes(include=[\"float64\", \"int64\"])\n",
        "        x_test_num = x_test.select_dtypes(include=[\"float64\", \"int64\"])\n",
        "        x_train_obj = x_train.select_dtypes(include=[\"object\"])\n",
        "        x_test_obj = x_test.select_dtypes(include=[\"object\"])\n",
        "\n",
        "        x_train_num_transformed = self.numerical_scaler.fit_transform(x_train_num, y_train)\n",
        "        x_train_obj_transformed = self.object_scaler.fit_transform(x_train_obj, y_train)\n",
        "\n",
        "        x_test_num_transformed = self.numerical_scaler.transform(x_test_num)\n",
        "        x_test_obj_transformed = self.object_scaler.transform(x_test_obj)\n",
        "\n",
        "        x_test_transformed = concatenate((x_test_num_transformed, x_test_obj_transformed), axis=1)\n",
        "        x_train_transformed = concatenate((x_train_num_transformed, x_train_obj_transformed), axis=1)\n",
        "\n",
        "        self.df_x_train_transformed = DataFrame(x_train_transformed, columns=x.columns)\n",
        "        self.df_x_test_transformed = DataFrame(x_test_transformed, columns=x.columns)\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def entrenar_modelo(self):\n",
        "        self.model = LinearRegression().fit(self.df_x_train_transformed, self.y_train)\n",
        "\n",
        "    def predecir(self):\n",
        "        return self.model.predict(self.df_x_test_transformed)\n",
        "\n",
        "    def guardar_modelo(self, modelo_path, scaler_path):\n",
        "        with open(modelo_path, 'wb') as modelo_file:\n",
        "            pickle.dump(self.model, modelo_file)\n",
        "        with open(scaler_path, 'wb') as scaler_file:\n",
        "            pickle.dump((self.numerical_scaler, self.object_scaler), scaler_file)\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_modelo(modelo_path, scaler_path, df=None):\n",
        "        modelo_predictivo = ModeloPredictivo(df)\n",
        "        with open(modelo_path, 'rb') as modelo_file:\n",
        "            modelo_predictivo.model = pickle.load(modelo_file)\n",
        "        with open(scaler_path, 'rb') as scaler_file:\n",
        "            modelo_predictivo.numerical_scaler, modelo_predictivo.object_scaler = pickle.load(scaler_file)\n",
        "        return modelo_predictivo\n",
        "\n",
        "    def ejecutar(self):\n",
        "        self.eliminar_duplicados()\n",
        "        self.convertir_reviews()\n",
        "        self.convertir_tamano()\n",
        "        self.convertir_installs()\n",
        "        self.imputar_nans()\n",
        "        self.imputar_outliers(['Reviews', 'Size', 'Installs'])\n",
        "        self.preparar_datos()\n",
        "        self.entrenar_modelo()\n",
        "        return self.predecir()\n",
        "\n",
        "\n",
        "# Uso de la clase\n",
        "\n",
        "# df_google = pd.read_csv(\"ruta_a_tu_csv.csv\")  # Cargar tus datos\n",
        "# modelo = ModeloPredictivo(df_google)\n",
        "# predicciones = modelo.ejecutar()\n",
        "# modelo.guardar_modelo('modelo_predictivo.pkl')\n",
        "\n",
        "# Para cargar el modelo y usarlo nuevamente\n",
        "# modelo_cargado = ModeloPredictivo.cargar_modelo('modelo_predictivo.pkl')\n",
        "# predicciones = modelo_cargado.predecir()\n",
        "# print(predicciones)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kiGyt5mKyhK-",
        "outputId": "2cc208b2-47e5-495c-fb7b-8ad02973bd3d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f4de32a2-64c6-412e-9edf-c27b6e0408b9\", \"df_x_train_transformed.pkl\", 499685)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2beb41de-6c91-43d4-8a7b-3d57d5a37124\", \"df_x_test_transformed.pkl\", 246533)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_488470da-b6f9-4ee4-b977-83d4c56eb953\", \"y_train.pkl\", 56124)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a2e024ba-9d55-448b-9038-fbdc279d88af\", \"y_test.pkl\", 27996)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Guardar el DataFrame en un archivo Pickle\n",
        "df_x_train_transformed.to_pickle('df_x_train_transformed.pkl')\n",
        "# Descargar el archivo Pickle\n",
        "from google.colab import files\n",
        "files.download('df_x_train_transformed.pkl')\n",
        "\n",
        "# Guardar el DataFrame en un archivo Pickle\n",
        "df_x_test_transformed.to_pickle('df_x_test_transformed.pkl')\n",
        "# Descargar el archivo Pickle\n",
        "from google.colab import files\n",
        "files.download('df_x_test_transformed.pkl')\n",
        "\n",
        "# Guardar el DataFrame en un archivo Pickle\n",
        "y_train.to_pickle('y_train.pkl')\n",
        "# Descargar el archivo Pickle\n",
        "from google.colab import files\n",
        "files.download('y_train.pkl')\n",
        "\n",
        "# Guardar el DataFrame en un archivo Pickle\n",
        "y_test.to_pickle('y_test.pkl')\n",
        "# Descargar el archivo Pickle\n",
        "from google.colab import files\n",
        "files.download('y_test.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
